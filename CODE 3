import numpy as np
import cv2
import collections
from collections import defaultdict
from collections import Counter
import pandas as pd
import smtplib

# location of video and first frame
file_path =r'INPUT VIDEO'
firstframe_path =r'INPUT IMAGE'

firstframe = cv2.imread(firstframe_path)

#---------------------------------
# Create Black Mask + Draw White Polygon on Black Mask
#---------------------------------

#BLACK :First mask - which is whole image black
mask = np.zeros(firstframe.shape[:2], dtype = "uint8") # (576, 720, 3), take (576,720) same height and width as the image
cv2.imshow('mask',mask) 

# WHITE: Update pts which is the Area of Interest
#pts = np.array([[280,80],[0,300],[0,500],[650,500],[650,80]], np.int32)
pts = np.array([[1600,1100],[950,1100],[700,100]], np.int32)

# Mask + white (255) + infill at '1'
#Docstring:   fillPoly(img, pts, color[, lineType[, shift[, offset]]]) -> None
cv2.fillPoly(mask,[pts],255,1)
cv2.imshow('Masked',mask)


#Read firstframe + BGR2GRAY + Gaussian Blur (ksize must be positive and odd) + show firstframe_blur
firstframe_masked = cv2.bitwise_and(firstframe,firstframe,mask=mask) #apply the mask
firstframe_gray = cv2.cvtColor(firstframe_masked, cv2.COLOR_BGR2GRAY)
#firstframe_blur = cv2.GaussianBlur(firstframe_gray,(17,17),0)
firstframe_blur= cv2.medianBlur(firstframe_gray,15)
#h3 = cv2.adaptiveThreshold(firstframe_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
cv2.imshow('Firstframe_blur',firstframe_blur)


cap = cv2.VideoCapture(file_path)

counter = 0
frameno =0


consecutiveframe=20

track_temp=[]
track_master=[]
track_temp2=[]

top_contour_dict = defaultdict(int)
obj_detected_dict = defaultdict(int)



frameno = 0
#Alert through mail
def sendMails():
    SenderAddress = "SENDERS EMAIL"  #ALLOW THIRD PARTY APPLICATION USAGE IN MAIL SETTING
    password = "PASSWORD"

    e = pd.read_excel("RECIVER EMAIL")  #CREATE A EXCEL SHEET AND ADD RECIVER'S MAIL UNDER HEADING "Emails"
    emails = e['Emails'].values
    server = smtplib.SMTP("smtp.gmail.com", 587)
    server.starttls()
    server.login(SenderAddress, password)
    msg = "Unattended object lying on path-XYZ"
    subject = "CLEAR THE PATH"
    body = "Subject: {}\n\n{}".format(subject,msg)
    for email in emails:
        server.sendmail(SenderAddress, email, body)
    server.quit()
    



while (cap.isOpened()):
    # read the frame ; 
    #Docstring:   read([, image]) -> retval, image
    ret, frame = cap.read()
    
    
    # have to check, else error on the last frame.
    if ret==0:
        break
    frameno = frameno + 1
    
    #-------------------------------------------------
    #Draw count line
    #-------------------------------------------------
    
    #Height = 400, Width = 600
    #cv2.line(frame,(100,150),(100,400),(0,255,0),2)
   
    #-------------------------------------------------
    #Frame + BGR2GRAY + Gaussian Blur + show frame_blur
    #-------------------------------------------------
    frame_masked = cv2.bitwise_and(frame,frame,mask=mask) #apply the mask
    frame_gray = cv2.cvtColor(frame_masked, cv2.COLOR_BGR2GRAY)
    #frame_blur = cv2.GaussianBlur(frame_gray,(17,17),0)
    frame_blur= cv2.medianBlur(frame_gray,15)
    #h4 = cv2.adaptiveThreshold(frame_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
    cv2.imshow('frame_blur',frame_blur)
    
    
    #Absolute difference between firstframe_blur and frame_blur+ show frame_difference
    frame_difference = cv2.absdiff(firstframe_blur, frame_blur)
    cv2.imshow('frame_difference',frame_difference)
    #h5 = cv2.adaptiveThreshold(frame_difference,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
    h5=cv2.threshold(frame_difference, 25 , 255, cv2.THRESH_BINARY)[1]

    #-------------------------------------------------------------
    #Canny Edge Detection (these are broken lines along the boundary)
    #-------------------------------------------------------------
    edged = cv2.Canny(h5,100,200) #any gradient between 30 and 150 are considered edges
    cv2.imshow('Edge',edged)
    
    # Set up kernel for Morphological Transformation
    kernel = np.ones((5,5),np.float32)/25 #higher the kernel, eg (10,10), more will be eroded or dilated
    
    # Choose either 1 or 2
    # Method 1: Dilate the Edges so that we can find contours
    thresh1 = cv2.dilate(edged, kernel, iterations=3)
    cv2.imshow('Dilate',thresh1)
    
    # Method 2 : morphologyEx (CLOSED)Dilation followed by Erosion**. 
    # It is useful in **closing small holes inside the foreground** objects, or small black points on the object.
    #Docstring:   morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst
    kernel2 = np.ones((5,5),np.float32)/25 #higher the kernel, eg (10,10), more will be eroded or dilated
    thresh2 = cv2.morphologyEx(edged,cv2.MORPH_CLOSE, kernel2,iterations=2)
    cv2.imshow('Morph_Close', thresh2)  
    
    
    #-------------------------------------------------------------
    #Create a copy of the thresh to find contours
    #-------------------------------------------------------------
    
    (_, cnts, _) = cv2.findContours(thresh1.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    #(_, cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
    
    #(_, cnts, _) = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    
    #cv2.putText(frame,'P', (100,250),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)
    

    mycnts =[] # every new frame, set to empty list. 
    # loop over the contours
    for c in cnts:


        # Calculate Centroid using cv2.moments
        M = cv2.moments(c)
        if M['m00'] == 0: 
            pass
        else:
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])


            #----------------------------------------------------------------
            # Set contour criteria
            #----------------------------------------------------------------
            
            if cv2.contourArea(c) < 1500 or cv2.contourArea(c)>200000:
                pass
            elif (cv2.contourArea(c)>5000 and cx<70):
                pass
            else:
                mycnts.append(c)
                
                # compute the bounding box for the contour, draw it on the frame,
                # and update the text
                (x, y, w, h) = cv2.boundingRect(c)
                cv2.rectangle(frame_masked, (x, y), (x + w, y + h), (0, 255, 0), 2)
                # putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])
                # org ; is the (x,y) location
                cv2.putText(frame_masked,'C %s,%s,%.0f'%(cx,cy,cx+cy), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)
                
                print(cv2.contourArea(c), cx, cy, frameno)
                
                #cv2.putText(frame,'%s,%s'%('Object',len(cnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)
                
                #Store the cx+cy, a single value into a list ; max length of 10000
                #Once hit 10000, tranfer top 20 points to dictionary ; empty list
                sumcxcy=cx+cy
                
                
                
                #track_list.append(cx+cy)
                track_temp.append([cx+cy,frameno])
                
                
                track_master.append([cx+cy,frameno])
                countuniqueframe = set(j for i, j in track_master) # get a set of unique frameno. then len(countuniqueframe)
                
                #print len(countuniqueframe), track_master # [sumcxcy,frameno]
                
                #----------------------------------------------------------------
                # Format of track_master
                # print 5 [[341, 76], [340, 77], [341, 78], [340, 79], [343, 80]]
                #----------------------------------------------------------------
                
                
                #----------------------------------------------------------------
                # Store history of frames ; no. of frames stored set by 'consecutiveframe' ;
                # if no. of no. of unique frames > consecutiveframes, then 'pop or remove' the earliest frame ; defined by
                # minframeno. Objective is to count the same values occurs in all the frames under this list. if yes, 
                # it is likely that it is a stationary object and not a passing object (walking) 
                # And the value is stored separately in top_contour_dict , and counted each time. This dict is the master
                # dict to store the list of suspecious object. Ideally, it should be a short list. if there is a long list
                # there will be many false detection. To keep the list short, increase the 'consecutiveframe'.
                # Keep the number of frames to , remove the minframeno.; but hard to remove, rather form a new list without
                #the minframeno.
                #----------------------------------------------------------------
                if len(countuniqueframe)>consecutiveframe: 
                    minframeno=min(j for i, j in track_master)
                    for i, j in track_master:
                        if j != minframeno: # get a new list. omit the those with the minframeno
                            track_temp2.append([i,j])
                
                    track_master=list(track_temp2) # transfer to the master list
                    track_temp2=[]
                    
                
                #print 'After',track_master
                
                #count each of the sumcxcy
                #if the same sumcxcy occurs in all the frames, store in master contour dictionary, add 1
                
                countcxcy = Counter(i for i, j in track_master)
                #print countcxcy
                #example countcxcy : Counter({544: 1, 537: 1, 530: 1, 523: 1, 516: 1})
                #if j which is the count occurs in all the frame, store the sumcxcy in dictionary, add 1
                for i,j in countcxcy.items(): 
                    if j>=consecutiveframe:
                        top_contour_dict[i] += 1
  
                
                if sumcxcy in top_contour_dict:
                    if top_contour_dict[sumcxcy]>100:
                        cv2.rectangle(frame_masked, (x, y), (x + w, y + h), (255, 0, 0), 3)
                        cv2.putText(frame_masked,'%s'%('CheckObject'), (cx,cy),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)
                        print('Detected :',sumcxcy,frameno, obj_detected_dict)
                        sendMails()
                
                    
                        # Store those objects that are detected, and store the last frame that it happened.
                        # Need to find a way to clean the top_contour_dict, else contour will be detected after the 
                        # object is removed because the value is still in the dict.
                        # Method is to record the last frame that the object is detected with the Current Frame (frameno)
                        # if Current Frame - Last Frame detected > some big number say 100 x 3, then it means that 
                        # object may have been removed because it has not been detected for 100x3 frames.
                        
                        obj_detected_dict[sumcxcy]=frameno

                

    for i, j in obj_detected_dict.items():
        if frameno - obj_detected_dict[i]>100:
            print('PopBefore',i, obj_detected_dict[i],frameno,obj_detected_dict)
            print('PopBefore : top_contour :',top_contour_dict)
            obj_detected_dict.pop(i)
            
            # Set the count for eg 448 to zero. because it has not be 'activated' for 200 frames. Likely, to have been removed.
            top_contour_dict[i]=0
            print('PopAfter',i, obj_detected_dict[i],frameno,obj_detected_dict)
            print('PopAfter : top_contour :',top_contour_dict)

                        
    
    
                
                 
               

    
    #cv2.putText(frame,'%s%s'%('Objects :',len(mycnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)

    #--------------------------------------
    #Draw the AreaofInterest on the frame
    #--------------------------------------
    cv2.polylines(frame_masked,[pts],True,(255,0,0),thickness=2)
    
    
    #--------------------------------------
    # Show images
    #--------------------------------------
        
    cv2.imshow('Abandoned Object Detection',frame_masked)
    cv2.putText(frame_masked,'%s%s'%('Objects :',len(mycnts)), (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)

    
 
    #show the frame
    #Docstring:   imshow(winname, mat) -> None
    cv2.imshow('Window',frame_masked)
    


    #control, press 'q' key to exit
    # Min cv2.waitKey(integer = min at 1) ; video will be fast ; increase integer value to slow the video    
    if cv2.waitKey(30) & 0xFF == ord('q'):
        break


#when everything is done, release cap
cap.release()
cv2.destroyAllWindows()
